# -*- coding: utf-8 -*-
"""okt+tfidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y9UzKae3GnGyxXc-ykKIRNhtKaTtUmXx
"""
import os
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

script_dir = os.path.dirname(__file__)
# 파일의 상대 경로를 지정
relative_path = "../../data/processed/Okt_dataset.csv"

# 상대 경로를 현재 스크립트 파일의 경로와 조합하여 파일 경로를 얻음
file_path = os.path.join(script_dir, relative_path)

# Excel 파일을 데이터프레임으로 읽어오기
df = pd.read_csv(file_path)

# 'hannanum_nouns' 열의 각 행의 문자열을 콤마로 분리하여 리스트로 변환
df['okt_nouns'] = df['okt_nouns'].apply(lambda x: x.split(','))

# TF-IDF 벡터화
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(df['okt_nouns'].apply(lambda x: ' '.join(x)))

# 중요한 단어들을 'tfidf' 열에 추가
important_words = tfidf_vectorizer.get_feature_names_out()
word_tfidf_mapping = {}

for i, row in enumerate(tfidf_matrix):
    print(i)
    word_tfidf_mapping[i] = {}
    for j, word_index in enumerate(row.indices):
        word = important_words[word_index]
        tfidf_score = row.data[j]
        word_tfidf_mapping[i][word] = tfidf_score

# TF-IDF 결과를 DataFrame 출력
# "imp_words" 열에서 콤마로 구분된 단어를 분리하고, 그 갯수에 따라 다른 갯수의 키워드 추출
df['okt_tfidf_keywords'] = df['imp_words'].apply(lambda words: list(word_tfidf_mapping[i].keys())[:len(words.split(','))])
df['okt_tfidf_scores'] = df['okt_tfidf_keywords'].apply(lambda keywords: [word_tfidf_mapping[i][keyword] for keyword in keywords])


n_script_dir = os.path.dirname(__file__)
n_relative_path = "../../data/result/okt_tfidf.csv"
n_file_path = os.path.join(n_script_dir, n_relative_path)
df.to_csv(n_file_path, index=False)
